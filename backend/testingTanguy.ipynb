{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import langchain\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "import os\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.llms import GPT4All,OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Determine the name of the environment variable you want to use for the OpenAPI key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'json',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'query',\n",
       " 'query_with_sources',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'vectorstore']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "print(os.environ['OPENAI_API_KEY'])\n",
    "loader = TextLoader('testarticles/articleIsrael.txt' )\n",
    "index_creator = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=Chroma, \n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    ").from_loaders([loader])\n",
    "\n",
    "index_creator.__class__.mro()\n",
    "[attr for attr in dir(index_creator) if attr.startswith('__') is False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanguyrenaudie/miniforge3/envs/language/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt_template = \"\"\"Use the context below to write a 100 word blog post about the topic below:\n",
    "    Context: {context}\n",
    "    Topic: {topic}\n",
    "    Blog post:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"topic\"]\n",
    ")\n",
    "\n",
    "llm = FakeListLLM(responses = ['France', 'Germany', 'Italy', 'Spain', 'United Kingdom', 'USA', 'China', 'India', 'Japan', 'Russia'])\n",
    "llm = HuggingFaceHub()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2009, donor countries promised to mobilize $100\n",
      "The World Bank and the donor countries that contro\n",
      "Getting new money in the door is important, but it\n",
      "For years, climate financing took a back seat to t\n",
      "[{'text': ' What'}, {'text': ' In'}, {'text': ' Give'}, {'text': ' In'}]\n"
     ]
    }
   ],
   "source": [
    "def getattributes(obj):\n",
    "    return [attr for attr in dir(obj) if attr.startswith('__') is False]\n",
    "\n",
    "def generate_blog_post(topic):\n",
    "    docs = index_creator.vectorstore.similarity_search(topic, k=4)\n",
    "    for k in range(4):\n",
    "        print(docs[k].page_content[:50])\n",
    "    inputs = [{\"context\": doc.page_content, \"topic\": topic} for doc in docs]\n",
    "    return chain.apply(inputs)\n",
    "\n",
    "generate_blog_post('donor countries promised')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma VectorStore Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def getDocs():\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                github_url = f\"{file}\"\n",
    "                yield Document(page_content=f.read(), metadata={\"source\": github_url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getDocs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sources \u001b[39m=\u001b[39m getDocs()\n\u001b[1;32m      3\u001b[0m source_chunks \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m splitter \u001b[39m=\u001b[39m CharacterTextSplitter(separator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, chunk_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, chunk_overlap\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getDocs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sources = getDocs()\n",
    "\n",
    "source_chunks = []\n",
    "splitter = CharacterTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=0)\n",
    "for source in sources:\n",
    "    print(source.metadata)\n",
    "    print(source.page_content[:50])\n",
    "    for chunk in splitter.split_text(source.page_content):\n",
    "        print(len(chunk))\n",
    "        source_chunks.append(Document(page_content=chunk, metadata=source.metadata))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m source_chunks\n",
      "\u001b[0;31mNameError\u001b[0m: name 'source_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "source_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m search_index \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39mfrom_documents(source_chunks, OpenAIEmbeddings(), persist_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdbdir\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m search_index\u001b[39m.\u001b[39mpersist()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'source_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "search_index = Chroma.from_documents(source_chunks, OpenAIEmbeddings(), persist_directory = 'dbdir')\n",
    "search_index.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getattributes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m getattributes(search_index)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getattributes' is not defined"
     ]
    }
   ],
   "source": [
    "getattributes(search_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3be928ca-d47e-11ed-8349-22414b0296f5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_index.add_texts([\"Ankush went to Princeton\"])\n",
    "search_index.add_documents([Document(page_content=\"Ankush went to Princeton\", metadata={'source': 'sentence1'})])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_LANGCHAIN_DEFAULT_COLLECTION_NAME', '_abc_impl', '_client', '_client_settings', '_collection', '_embedding_function', '_persist_directory', 'add_documents', 'add_texts', 'as_retriever', 'delete_collection', 'from_documents', 'from_texts', 'max_marginal_relevance_search', 'max_marginal_relevance_search_by_vector', 'persist', 'similarity_search', 'similarity_search_by_vector', 'similarity_search_with_score']\n"
     ]
    }
   ],
   "source": [
    "print(getattributes(search_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'love'\n",
    "docs = search_index.similarity_search(topic, k=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New index from saved pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub()\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "def generatefromsaved():\n",
    "    docs = index_creator.vectorstore.similarity_search(topic, k=4)\n",
    "    inputs = [{\"context\": doc.page_content, \"topic\": topic} for doc in docs]\n",
    "    print(chain.apply(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: dbdir\n"
     ]
    }
   ],
   "source": [
    "vectorstore2 =  Chroma(persist_directory='dbdir', embedding_function=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "llm = LlamaCpp(model_path=\"./ggml-model-q4_0.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: dbdir2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'TODO.txt'}\n",
      "- update getChunks. From a number of temp .txt fil\n",
      "501\n",
      "{'source': 'article.txt'}\n",
      "Humanity Is Facing a Great Injustice. The World Ba\n",
      "507\n",
      "507\n",
      "508\n",
      "510\n",
      "508\n",
      "507\n",
      "508\n",
      "511\n",
      "508\n",
      "509\n",
      "65\n",
      "{'source': 'article4.txt'}\n",
      "Le mod`ele lin ́eaire est souvent le premier outil\n",
      "511\n",
      "503\n",
      "502\n",
      "90\n",
      "{'source': 'article2.txt'}\n",
      "The Income Gap Is Becoming a Physical-Activity Div\n",
      "508\n",
      "510\n",
      "510\n",
      "510\n",
      "507\n",
      "509\n",
      "507\n",
      "511\n",
      "510\n",
      "288\n",
      "{'source': 'article3.txt'}\n",
      "Israel Is Courting Disaster\n",
      "March 5, 2023\n",
      "By Micha\n",
      "512\n",
      "510\n",
      "508\n",
      "508\n",
      "499\n",
      "512\n",
      "512\n",
      "511\n",
      "510\n",
      "504\n",
      "510\n",
      "507\n",
      "222\n"
     ]
    }
   ],
   "source": [
    "def getDocs():\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                github_url = f\"{file}\"\n",
    "                yield Document(page_content=f.read(), metadata={\"source\": github_url})\n",
    "\n",
    "sources = getDocs()\n",
    "source_chunks = []\n",
    "splitter = CharacterTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=0)\n",
    "for source in sources:\n",
    "    print(source.metadata)\n",
    "    print(source.page_content[:50])\n",
    "    for chunk in splitter.split_text(source.page_content):\n",
    "        print(len(chunk))\n",
    "        source_chunks.append(Document(page_content=chunk, metadata=source.metadata))\n",
    "        \n",
    "vectorstore = Chroma.from_documents(getDocs(), OpenAIEmbeddings(), persist_directory = 'dbdir2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: dbdir\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma(embedding_function =  OpenAIEmbeddings(), persist_directory = 'dbdir')\n",
    "vectorstore.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f879a872-d69d-11ed-9594-22414b0296f5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents([Document(page_content=\"Ankush went to Princeton a fourht time!\", metadata={'source': 'sentence4'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore._client._count('langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = Document(page_content=\"Ankush went to Princeton a fourht time!\", metadata={'source': 'sentence4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1.page_content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some random content from the vectorstore - Vector DB Text Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-09 08:48:54,866] {posthog.py:15} INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "[2023-04-09 08:48:54,869] {__init__.py:80} INFO - Running Chroma using direct local API.\n",
      "[2023-04-09 08:48:54,870] {__init__.py:41} WARNING - Using embedded DuckDB with persistence: data will be stored in: dbdir\n",
      "[2023-04-09 08:48:54,924] {duckdb.py:430} INFO - loaded in 14 embeddings\n",
      "[2023-04-09 08:48:54,926] {duckdb.py:440} INFO - loaded in 1 collections\n",
      "[2023-04-09 08:48:54,927] {duckdb.py:85} INFO - collection with name langchain already exists, returning existing collection\n",
      "[2023-04-09 08:48:54,929] {duckdb.py:445} INFO - PersistentDuckDB del, about to run persist\n",
      "[2023-04-09 08:48:54,929] {duckdb.py:388} INFO - Persisting DB to disk, putting it in the save folder: dbdir\n",
      "[2023-04-09 08:48:54,936] {duckdb.py:388} INFO - Persisting DB to disk, putting it in the save folder: dbdir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load: loading model from '../../gpt4all_model/gpt4all-converted.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32001\n",
      "llama_model_load: n_ctx   = 512\n",
      "llama_model_load: n_embd  = 4096\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 32\n",
      "llama_model_load: n_layer = 32\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 11008\n",
      "llama_model_load: n_parts = 1\n",
      "llama_model_load: type    = 1\n",
      "llama_model_load: ggml map size = 4017.70 MB\n",
      "llama_model_load: ggml ctx size =  81.25 KB\n",
      "llama_model_load: mem required  = 5809.78 MB (+ 2052.00 MB per state)\n",
      "llama_model_load: loading tensors from '../../gpt4all_model/gpt4all-converted.bin'\n",
      "llama_model_load: model size =  4017.27 MB / num tensors = 291\n",
      "llama_init_from_file: kv self size  =  512.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'context': 'Constitution is not perfect — no law is — but its\\nmany checks and balances have been essential to protecting and advancing fundamental rights and\\nmaintaining national stability. It was only through those safeguards that the United States has managed to\\nwithstand extreme shocks to our democracy in recent years — including a disgraceful attempt to prevent\\nthe peaceful transfer of power — without a catastrophic fracturing.\\nIn withstanding those shocks, the United States also has had a luxury that Israel does', 'topic': 'usa'}, {'context': 'partly on a relationship with the United\\nStates built on shared values — freedom, equality, democracy — that can only be sustained by a\\ncommitment to the rule of law, including an independent judiciary capable of upholding it. If Israel\\nretreats from that long-term commitment and moves its model of governance toward one that mirrors\\nthose of authoritarian countries, it risks weakening its ties to the United States and other free nations.\\nThat would be a devastating loss for Israel’s security, harm prospects', 'topic': 'usa'}, {'context': 'the country’s economy,\\ngiven air travel is the only practical way to get in and out for nearly all travelers. I wanted to stand with\\nIsrael against Hamas, by highlighting the safety of travel to Israel and urging the Obama administration to\\nreverse course — which it soon did, to its credit.\\nGreeting me on the tarmac that day was Prime Minister Benjamin Netanyahu. He thanked me for my\\nsupport, and I thanked him for Israel’s support of New York City and the United States after the Sept. 11\\nattacks. Close', 'topic': 'usa'}, {'context': 'for a peaceful resolution of the\\nPalestinian conflict and could even imperil the future of the Jewish homeland. It would also undermine\\nthe deep attachment millions of people around the world feel toward the country, often because of the\\npride our parents instilled in us not only for its Jewish character but also for its strong commitment to\\nfreedom.\\nIn the United States, our founding fathers’ insistence on checks and balances to control the tyrannical\\ntendencies of majorities was part of their genius. Our', 'topic': 'usa'}]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_generate: seed = 1681022935\n",
      "\n",
      "system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "sampling: temp = 0.800000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000\n",
      "generate: n_ctx = 512, n_batch = 1, n_predict = 256, n_keep = 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma(embedding_function =  OpenAIEmbeddings(), persist_directory = 'dbdir')\n",
    "vectorstore.persist()\n",
    "prompt = 'give me a summary of the data i gave you'\n",
    "huggingface_hub_api_key = \"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\"\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_hub_api_key\n",
    "\n",
    "prompt_template = \"\"\"Use the context below to write a 400 word blog post about the topic below:\n",
    "    Context: {context}\n",
    "    Topic: {topic}\n",
    "    Blog post:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"topic\"]\n",
    ")\n",
    "\n",
    "llm = HuggingFaceHub()\n",
    "llm_gpt4all =  GPT4All(model=\"../../gpt4all_model/gpt4all-converted.bin\")\n",
    "llm_openai = OpenAI()\n",
    "chain = LLMChain(llm=llm_gpt4all, prompt=PROMPT)\n",
    "topic = 'usa'\n",
    "docs = vectorstore.similarity_search(topic, k=4)\n",
    "inputs = [{\"context\": doc.page_content, \"topic\": topic} for doc in docs]\n",
    "print(inputs)\n",
    "print(len(inputs))\n",
    "print(chain.apply(inputs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[langchain.vectorstores.chroma.Chroma,\n",
       " langchain.vectorstores.base.VectorStore,\n",
       " abc.ABC,\n",
       " object]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.__class__.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
